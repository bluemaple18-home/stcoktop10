#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PSI (Population Stability Index) æ¼‚ç§»ç›£æŽ§æ¨¡çµ„
åŠŸèƒ½: åµæ¸¬ç‰¹å¾µåˆ†ä½ˆè®ŠåŒ–ï¼Œä¸¦åœ¨å¿…è¦æ™‚è§¸ç™¼é‡è¨“è­¦å‘Š
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import json
import warnings
warnings.filterwarnings('ignore')

class ModelMonitor:
    """æ¨¡åž‹æ¼‚ç§»ç›£æŽ§å™¨"""
    
    def __init__(self, data_dir: str = "data/clean", 
                 baseline_path: str = "models/baseline_stats.json",
                 psi_warning: float = 0.25,
                 psi_critical: float = 0.5):
        """
        Args:
            baseline_path: åŸºæº–çµ±è¨ˆè³‡æ–™è·¯å¾‘ (è¨“ç·´é›†åˆ†ä½ˆ)
            psi_warning: PSI è­¦å‘Šé–¾å€¼
            psi_critical: PSI åš´é‡é–¾å€¼
        """
        self.data_dir = Path(data_dir)
        self.baseline_path = Path(baseline_path)
        self.psi_warning = psi_warning
        self.psi_critical = psi_critical
        
    def calculate_psi(self, expected: pd.Series, actual: pd.Series, bins: int = 10) -> float:
        """
        è¨ˆç®— PSI (Population Stability Index)
        
        Args:
            expected: åŸºæº–åˆ†ä½ˆ (è¨“ç·´é›†)
            actual: å¯¦éš›åˆ†ä½ˆ (æœ€è¿‘è³‡æ–™)
            bins: åˆ†æ¡¶æ•¸é‡
            
        Returns:
            psi_value: PSI æ•¸å€¼
        """
        # ç§»é™¤ NaN
        expected = expected.dropna()
        actual = actual.dropna()
        
        if len(expected) == 0 or len(actual) == 0:
            return 0.0
            
        # è¨ˆç®—åˆ†ä½æ•¸é‚Šç•Œ (åŸºæ–¼ expected)
        try:
            breakpoints = np.percentile(expected, np.linspace(0, 100, bins + 1))
            breakpoints = np.unique(breakpoints)  # åŽ»é‡
        except:
            return 0.0
            
        # è¨ˆç®—å„å€é–“çš„ç™¾åˆ†æ¯”
        expected_percents = np.histogram(expected, bins=breakpoints)[0] / len(expected)
        actual_percents = np.histogram(actual, bins=breakpoints)[0] / len(actual)
        
        # PSI è¨ˆç®—
        psi_value = 0
        for exp, act in zip(expected_percents, actual_percents):
            # é¿å…é™¤ä»¥é›¶
            if exp == 0:
                exp = 0.0001
            if act == 0:
                act = 0.0001
            psi_value += (act - exp) * np.log(act / exp)
            
        return psi_value
    
    def save_baseline(self):
        """å„²å­˜è¨“ç·´é›†ç‰¹å¾µåˆ†ä½ˆä½œç‚ºåŸºæº–"""
        print("ðŸ“Š å„²å­˜è¨“ç·´é›†åŸºæº–çµ±è¨ˆ...")
        
        features_path = self.data_dir / "features.parquet"
        if not features_path.exists():
            print("âŒ æ‰¾ä¸åˆ°ç‰¹å¾µæª”æ¡ˆ")
            return
            
        df = pd.read_parquet(features_path)
        
        # åªä¿ç•™æ•¸å€¼ç‰¹å¾µ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        # æŽ’é™¤ ID èˆ‡æ¨™ç±¤
        exclude = ['stock_id', 'date', 'target', 'return_5d', 'future_return', 'return_long']
        numeric_cols = [c for c in numeric_cols if c not in exclude]
        
        # è¨ˆç®—çµ±è¨ˆé‡ (mean, std, min, max, quantiles)
        baseline_stats = {}
        for col in numeric_cols:
            data = df[col].dropna()
            if len(data) > 0:
                baseline_stats[col] = {
                    'mean': float(data.mean()),
                    'std': float(data.std()),
                    'min': float(data.min()),
                    'max': float(data.max()),
                    'q25': float(data.quantile(0.25)),
                    'q50': float(data.quantile(0.50)),
                    'q75': float(data.quantile(0.75)),
                    'distribution': data.values.tolist()[:1000]  # ä¿ç•™éƒ¨åˆ†æ¨£æœ¬
                }
        
        # å„²å­˜
        baseline_stats['metadata'] = {
            'created_at': datetime.now().isoformat(),
            'total_samples': len(df),
            'features_count': len(baseline_stats) - 1
        }
        
        with open(self.baseline_path, 'w') as f:
            json.dump(baseline_stats, f, indent=2)
            
        print(f"âœ… åŸºæº–çµ±è¨ˆå·²å„²å­˜: {self.baseline_path}")
        print(f"   - æ¨£æœ¬æ•¸: {len(df)}")
        print(f"   - ç‰¹å¾µæ•¸: {len(baseline_stats) - 1}")
    
    def check_drift(self, days: int = 30) -> dict:
        """
        æª¢æŸ¥æœ€è¿‘ N å¤©çš„è³‡æ–™æ˜¯å¦æ¼‚ç§»
        
        Args:
            days: æª¢æŸ¥æœ€è¿‘å¹¾å¤©çš„è³‡æ–™
            
        Returns:
            drift_report: æ¼‚ç§»å ±å‘Š
        """
        print(f"\nðŸ“Š æª¢æŸ¥æœ€è¿‘ {days} å¤©çš„è³‡æ–™æ¼‚ç§»...")
        
        # è¼‰å…¥åŸºæº–
        if not self.baseline_path.exists():
            print("âš ï¸ æœªæ‰¾åˆ°åŸºæº–çµ±è¨ˆï¼Œè«‹å…ˆåŸ·è¡Œ save_baseline()")
            return {'status': 'no_baseline'}
            
        with open(self.baseline_path, 'r') as f:
            baseline_stats = json.load(f)
            
        # è¼‰å…¥æœ€è¿‘è³‡æ–™
        features_path = self.data_dir / "features.parquet"
        df = pd.read_parquet(features_path)
        df = df.sort_values('date')
        
        # ç¯©é¸æœ€è¿‘ N å¤©
        cutoff_date = df['date'].max() - pd.Timedelta(days=days)
        recent_df = df[df['date'] > cutoff_date]
        
        print(f"   - åŸºæº–è³‡æ–™: {baseline_stats['metadata']['total_samples']} ç­†")
        print(f"   - æœ€è¿‘è³‡æ–™: {len(recent_df)} ç­† ({cutoff_date.date()} ~ {df['date'].max().date()})")
        
        # è¨ˆç®— PSI
        psi_results = {}
        numeric_cols = [k for k in baseline_stats.keys() if k != 'metadata']
        
        for col in numeric_cols:
            if col not in recent_df.columns:
                continue
                
            baseline_dist = pd.Series(baseline_stats[col]['distribution'])
            recent_dist = recent_df[col].dropna()
            
            psi = self.calculate_psi(baseline_dist, recent_dist)
            psi_results[col] = psi
        
        # æ‰¾å‡ºé«˜ PSI çš„ç‰¹å¾µ
        high_psi = {k: v for k, v in psi_results.items() if v > self.psi_warning}
        critical_psi = {k: v for k, v in psi_results.items() if v > self.psi_critical}
        
        # æ•´é«” PSI (å¹³å‡)
        avg_psi = np.mean(list(psi_results.values()))
        
        # åˆ¤å®šçµæžœ
        if avg_psi > self.psi_critical:
            status = 'CRITICAL'
            action = 'ðŸš¨ å»ºè­°ç«‹å³é‡è¨“æ¨¡åž‹'
        elif avg_psi > self.psi_warning:
            status = 'WARNING'
            action = 'âš ï¸ å»ºè­°è¿‘æœŸé‡è¨“æ¨¡åž‹'
        else:
            status = 'OK'
            action = 'âœ… æ¨¡åž‹ç‹€æ…‹è‰¯å¥½'
        
        # ç”¢ç”Ÿå ±å‘Š
        drift_report = {
            'status': status,
            'action': action,
            'avg_psi': avg_psi,
            'warning_features': len(high_psi),
            'critical_features': len(critical_psi),
            'top_drift_features': sorted(psi_results.items(), key=lambda x: x[1], reverse=True)[:5],
            'timestamp': datetime.now().isoformat()
        }
        
        # é¡¯ç¤ºçµæžœ
        print(f"\n{'='*50}")
        print(f"ðŸ“ˆ PSI æ¼‚ç§»ç›£æŽ§å ±å‘Š")
        print(f"{'='*50}")
        print(f"æ•´é«” PSI: {avg_psi:.4f}")
        print(f"ç‹€æ…‹: {status}")
        print(f"{action}")
        print(f"\nâš ï¸ è­¦å‘Šç‰¹å¾µæ•¸: {len(high_psi)} (PSI > {self.psi_warning})")
        print(f"ðŸš¨ åš´é‡ç‰¹å¾µæ•¸: {len(critical_psi)} (PSI > {self.psi_critical})")
        
        if high_psi:
            print(f"\nTop 5 æ¼‚ç§»ç‰¹å¾µ:")
            for feat, psi in drift_report['top_drift_features']:
                print(f"  - {feat}: {psi:.4f}")
        
        print(f"{'='*50}\n")
        
        return drift_report


if __name__ == "__main__":
    monitor = ModelMonitor()
    
    # è‹¥ç„¡åŸºæº–ï¼Œå…ˆå»ºç«‹
    if not monitor.baseline_path.exists():
        print("ðŸ”§ é¦–æ¬¡åŸ·è¡Œï¼Œå»ºç«‹åŸºæº–çµ±è¨ˆ...")
        monitor.save_baseline()
    
    # åŸ·è¡Œæ¼‚ç§»æª¢æŸ¥
    report = monitor.check_drift(days=30)
    
    # å„²å­˜å ±å‘Š
    report_path = Path("artifacts/psi_report.json")
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    print(f"ðŸ“„ å ±å‘Šå·²å„²å­˜: {report_path}")
