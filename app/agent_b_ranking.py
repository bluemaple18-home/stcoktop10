
import pandas as pd
import numpy as np
import lightgbm as lgb
import yaml
from pathlib import Path
from datetime import datetime
import pickle
import logging
import shap

# æ–°å¢ï¼šå ±å‘Šç”Ÿæˆå™¨
try:
    from report_generator import StockReportGenerator
except ImportError:
    from app.report_generator import StockReportGenerator

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class StockRanker:
    """è‚¡ç¥¨æ’åå™¨ (Advancedç‰ˆ)ï¼šèåˆæ ¡æº–å¾Œçš„æ¨¡å‹æ©Ÿç‡ã€è¦å‰‡åˆ†æ•¸èˆ‡ SHAP è§£é‡‹"""
    
    # æŠ€è¡“æŒ‡æ¨™ä¸­è‹±å°ç…§è¡¨
    SIGNAL_TRANSLATIONS = {
        'break_20d_high': 'çªç ´20æ—¥æ–°é«˜',
        'rebound_ma20': 'æœˆç·šæ”¯æ’åå½ˆ',
        'close_above_bb_mid': 'ç«™ä¸Šå¸ƒæ—ä¸­è»Œ',
        'macd_bullish_cross': 'MACDé»ƒé‡‘äº¤å‰',
        'gap_up_close_strong': 'è·³ç©ºå¼·å‹¢æ”¶ç´…',
        'volume_spike': 'æˆäº¤é‡æš´å¢',
        'ma5_cross_ma20_up': '5æ—¥ç·šçªç ´æœˆç·š',
        'rsi_oversold_bounce': 'RSIè¶…è³£åå½ˆ',
        'kd_golden_cross': 'KDé»ƒé‡‘äº¤å‰',
        'break_60d_high': 'çªç ´60æ—¥æ–°é«˜',
        'volume_ma_breakout': 'é‡èƒ½çªç ´å‡é‡',
        'bullish_engulfing': 'å¤šé ­åå™¬Kç·š',
        'hammer': 'éŒ˜å­ç·šå‹æ…‹',
        'morning_star': 'æ™¨æ˜Ÿåè½‰',
    }
    
    def __init__(self, data_dir: str = "data/clean", model_dir: str = "models",
                 artifact_dir: str = "artifacts", config_path: str = "config/signals.yaml"):
        """
        åˆå§‹åŒ–æ’åå™¨
        """
        self.data_dir = Path(data_dir)
        self.model_dir = Path(model_dir)
        self.artifact_dir = Path(artifact_dir)
        self.config_path = Path(config_path)
        self.model = None
        self.calibrator = None
        
        # è¼‰å…¥è¨­å®š
        self.config = self._load_config()
        self.weights = self.config['scoring']['weights']
        # Alpha: æ¨¡å‹åˆ†æ•¸æ¬Šé‡ (é è¨­ 0.5)
        self.alpha = self.config['scoring'].get('alpha', 0.5)
        self.top_n = 10
        
        # å»ºç«‹å¿…è¦ç›®éŒ„
        self.artifact_dir.mkdir(parents=True, exist_ok=True)
    
    def _load_config(self):
        """è¼‰å…¥è¨Šè™Ÿè¨­å®š"""
        if not self.config_path.exists():
            logger.warning(f"è¨­å®šæª” {self.config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é è¨­å€¼")
            return {
                'scoring': {
                    'weights': {
                         'rebound_ma20': 1.0,
                         'break_20d_high': 1.5
                    },
                    'alpha': 0.5
                }
            }
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def load_model(self, filename: str = "latest_lgbm.pkl"):
        """è¼‰å…¥æ¨¡å‹ (æ”¯æ´ Old Booster or New Dict)"""
        model_path = self.model_dir / filename
        if not model_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
            
        with open(model_path, 'rb') as f:
            obj = pickle.load(f)
            
        if isinstance(obj, dict):
            self.model = obj['model']
            self.calibrator = obj.get('calibrator')
            logger.info(f"âœ“ å·²è¼‰å…¥æ¨¡å‹èˆ‡æ ¡æº–å™¨: {filename}")
        else:
            self.model = obj
            self.calibrator = None
            logger.info(f"âœ“ å·²è¼‰å…¥èˆŠç‰ˆæ¨¡å‹ (ç„¡æ ¡æº–): {filename}")

    def load_daily_data(self, date: str = None) -> tuple:
        """è¼‰å…¥ç•¶æ—¥è³‡æ–™"""
        features_path = self.data_dir / "features.parquet"
        universe_path = self.data_dir / "universe.parquet"
        
        if not features_path.exists():
             raise FileNotFoundError("æ‰¾ä¸åˆ°ç‰¹å¾µæª”æ¡ˆ (features.parquet)")
        
        features = pd.read_parquet(features_path)
        
        if universe_path.exists():
            universe = pd.read_parquet(universe_path)
            if universe.empty:
                logger.warning("universe.parquet æ˜¯ç©ºçš„ï¼Œä½¿ç”¨ features æ‰€æœ‰è‚¡ç¥¨")
                universe = pd.DataFrame({'stock_id': features['stock_id'].unique()})
        else:
            universe = pd.DataFrame({'stock_id': features['stock_id'].unique()})

        if date:
            target_date = pd.to_datetime(date)
        else:
            target_date = features['date'].max()
            
        logger.info(f"è¼‰å…¥æ—¥æœŸ: {target_date}")
        
        # å„ªåŒ–ï¼šåªä¿ç•™æœ€è¿‘ 90 å¤©ä»¥åŠ é€Ÿ Rolling è¨ˆç®—
        start_date = target_date - pd.Timedelta(days=90)
        features = features[features['date'] >= start_date].copy()
        
        # é è¨ˆç®—ï¼šå£“åŠ›ç·š (è¿‘20æ—¥é«˜é»ï¼Œä¸å«ä»Šæ—¥)
        features['ref_high_20d'] = features.groupby('stock_id')['high'].transform(lambda x: x.shift(1).rolling(20).max())
        features['ref_high_60d'] = features.groupby('stock_id')['high'].transform(lambda x: x.shift(1).rolling(60).max())
        
        daily_features = features[features['date'] == target_date].copy()
        
        if 'date' in universe.columns:
            daily_universe = universe[universe['date'] == target_date].copy()
        else:
            daily_universe = universe

        valid_stocks = daily_universe['stock_id'].unique()
        df = daily_features[daily_features['stock_id'].isin(valid_stocks)].copy()
        
        # ç¢ºä¿ float32 (LightGBM éœ€æ±‚)
        float_cols = df.select_dtypes(include=['float64']).columns
        if len(float_cols) > 0:
            df[float_cols] = df[float_cols].astype('float32')
            
        return df, features # Return both daily and history

    def calculate_scores(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¨ˆç®—ç¸½åˆ† (å«æ ¡æº–æ©Ÿç‡)"""
        df = df.copy()
        
        # 1. æ¨¡å‹é æ¸¬åˆ†æ•¸ (Win Prob)
        if self.model:
            model_features = self.model.feature_name()
            # è£œç¼ºå€¼
            for f in model_features:
                if f not in df.columns:
                    df[f] = 0
            
            X = df[model_features]
            # Predict Raw
            raw_prob = self.model.predict(X)
            df['raw_prob'] = raw_prob
            
            # Calibrate if available
            if self.calibrator:
                # IsotonicRegression.predict expects 1D array
                df['model_prob'] = self.calibrator.predict(raw_prob)
            else:
                df['model_prob'] = raw_prob
        else:
            df['model_prob'] = 0.5 
            df['raw_prob'] = 0.5
            
        # 2. è¦å‰‡åˆ†æ•¸ (Rule Score)
        df['rule_score'] = 0.0
        df['reasons'] = "" # Rule-based reasons
        
        for signal, weight in self.weights.items():
            if signal in df.columns:
                val = df[signal].fillna(0).astype(float)
                triggered = val > 0
                df.loc[triggered, 'rule_score'] += weight
                
                reason_mask = triggered
                # ä½¿ç”¨ä¸­æ–‡ç¿»è­¯ï¼ˆå¦‚æœ‰ï¼‰
                display_name = self.SIGNAL_TRANSLATIONS.get(signal, signal)
                tag = f"{display_name}(+{weight}) " if weight > 0 else f"{display_name}({weight}) "
                
                if reason_mask.any():
                    # æš«å­˜åŸå§‹è¨Šè™Ÿï¼Œç¨å¾Œçµ±ä¸€çµ„è£æ¨¡æ¿
                    # df.loc[reason_mask, 'reasons'] = df.loc[reason_mask, 'reasons'] + tag
                    # é€™è£¡æ”¹ç‚ºç”¨ä¸€å€‹ new column å­˜ raw signals
                    if 'raw_signals' not in df.columns:
                        df['raw_signals'] = ""
                    df.loc[reason_mask, 'raw_signals'] = df.loc[reason_mask, 'raw_signals'] + tag
        
        # çµ„è£å®Œæ•´æ¨¡æ¿
        # éœ€è¦è¨ˆç®—ï¼šæ­¢æ(MA20 or Low*0.95)ã€ç›®æ¨™(Close*1.1)
        # æ ¼å¼ï¼š
        # **ğŸ¯ æ“ä½œç­–ç•¥**
        # â€¢ é€²å ´ï¼š{Close}
        # â€¢ æ­¢æï¼š{Stop_Loss} ({Note})
        # â€¢ ç›®æ¨™ï¼š{Target} (+10%)
        #
        # **ğŸ’¡ é—œéµç†ç”±**
        # â€¢ {Reason 1}
        # â€¢ {Reason 2}
        
        reasons_formatted = []
        for idx, row in df.iterrows():
            close = row.get('close', 0)
            ma20 = row.get('ma20', 0)
            
            # ç­–ç•¥è¨ˆç®—
            if ma20 > 0 and close > ma20:
                stop_loss = ma20 * 0.98 # æœˆç·šä¸‹æ–¹ä¸€é»é»
                stop_note = "æœˆç·šæ”¯æ’"
            else:
                stop_loss = close * 0.95
                stop_note = "å›æª”5%"
                
            target_price = close * 1.1 # é è¨­ 10% ç²åˆ©
            
            # è§£æåŸå§‹è¨Šè™Ÿ
            raw_sigs = row.get('raw_signals', '').strip()
            # ç§»é™¤åˆ†æ•¸æ‹¬è™Ÿï¼Œåªç•™ä¸­æ–‡åç¨±
            import re
            clean_sigs = re.sub(r'\([+-]?\d+\.?\d*\)', '', raw_sigs).split()
            
            # çµ„åˆæ¨¡æ¿
            tpl = f"""**ğŸ¯ æ“ä½œç­–ç•¥**  
â€¢ é€²å ´ï¼š{close:.1f}  
â€¢ æ­¢æï¼š{stop_loss:.1f} ({stop_note})  
â€¢ ç›®æ¨™ï¼š{target_price:.1f} (+10%)  

**ğŸ’¡ é—œéµç†ç”±**  
"""
            if clean_sigs:
                # è±å¯ŒåŒ–ç†ç”± (åŠ å…¥å…·é«”æ•¸å€¼)
                enriched_sigs = []
                for s in clean_sigs[:3]:
                    if 'çªç ´20æ—¥' in s:
                        prior_high = row.get('ref_high_20d', 0)
                        if prior_high > 0:
                            s = f"{s} (å£“åŠ›{prior_high:.1f})"
                    if 'çªç ´60æ—¥' in s:
                        prior_high = row.get('ref_high_60d', 0)
                        if prior_high > 0:
                            s = f"{s} (å£“åŠ›{prior_high:.1f})"
                    if 'æœˆç·šæ”¯æ’' in s:
                        s = f"{s} (MA20:{ma20:.1f})"
                    if 'é»ƒé‡‘äº¤å‰' in s:
                        # æ¨™è¨»æ—¥æœŸ (ç•¶æ—¥)
                        date_str = row['date'].strftime('%m/%d') if 'date' in row else ""
                        s = f"{s} ({date_str})"
                    enriched_sigs.append(s)
                    
                tpl += "  \n".join([f"â€¢ {s}" for s in enriched_sigs])
            else:
                tpl += "â€¢ ç¶œåˆæŠ€è¡“æŒ‡æ¨™è½‰å¼·"
                
            reasons_formatted.append(tpl)
            
        df['reasons'] = reasons_formatted
        
        # 3. è¦å‰‡åˆ†æ•¸æ­£è¦åŒ–
        max_score = df['rule_score'].max()
        min_score = df['rule_score'].min()
        if max_score > min_score:
            df['rule_score_norm'] = (df['rule_score'] - min_score) / (max_score - min_score)
        else:
            df['rule_score_norm'] = 0.5
            
        # 4. èåˆ (æ”¹ç”¨ raw_prob ä»¥ä¿ç•™ AI æ’åºèƒ½åŠ›)
        df['final_score'] = self.alpha * df['raw_prob'] + (1 - self.alpha) * df['rule_score_norm']
        df = df.sort_values('final_score', ascending=False)
        return df
        
    def _enrich_with_shap(self, df: pd.DataFrame, top_n: int = 20) -> pd.DataFrame:
        """ç‚º Top N è‚¡ç¥¨å¢åŠ  SHAP AI è§£é‡‹"""
        if self.model is None: return df
        
        # åªå–å‰ N ååšè§£é‡‹ (åŠ é€Ÿ)
        top_df = df.head(top_n).copy()
        
        try:
            model_features = self.model.feature_name()
            X_top = top_df[model_features]
            
            # å»ºç«‹ Explainer (TreeExplainer)
            explainer = shap.TreeExplainer(self.model)
            shap_values = explainer.shap_values(X_top)
            
            # shap_values å¯èƒ½æ˜¯ list (Binary case sometimes returns [neg, pos])
            if isinstance(shap_values, list):
                shap_values = shap_values[1] # å– Positive class contribution
                
            # ç‚ºæ¯ä¸€åˆ—ç”Ÿæˆ "AI Reason"
            ai_reasons = []
            for i in range(len(top_df)):
                # æ‰¾å‡ºè²¢ç»æœ€å¤§çš„å‰ 3 å€‹ç‰¹å¾µ
                vals = shap_values[i]
                # sort indices
                top_indices = np.argsort(np.abs(vals))[-3:][::-1] # absolute value biggest 3
                
                reason_parts = []
                for idx in top_indices:
                    feat_name = model_features[idx]
                    contrib = vals[idx]
                    # åªé¡¯ç¤ºæœ‰æ„ç¾©çš„è²¢ç» (> 0.01 æˆ– < -0.01 margin)
                    if abs(contrib) > 0.01:
                        sign = "+" if contrib > 0 else ""
                        reason_parts.append(f"{feat_name}({sign}{contrib:.2f})")
                
                if reason_parts:
                    ai_reasons.append(" | AI: " + " ".join(reason_parts))
                else:
                    ai_reasons.append("")
            
            top_df['reasons'] = top_df['reasons'] + pd.Series(ai_reasons, index=top_df.index)
            
            # æ›´æ–°å›åŸå§‹ DF
            df.loc[top_df.index, 'reasons'] = top_df['reasons']
            
        except Exception as e:
            logger.warning(f"SHAP è§£é‡‹ç”Ÿæˆå¤±æ•—: {e}")
            
        return df

    def run_ranking(self, date: str = None):
        """åŸ·è¡Œæ’åä¸»æµç¨‹"""
        try:
            # Load Data
            df, history_df = self.load_daily_data(date)
            if df.empty:
                logger.warning("ç„¡è³‡æ–™å¯æ’å")
                return
            
            # Calc Scores
            rank_df = self.calculate_scores(df)
            
            # Enrich with SHAP (Before saving Top 10)
            rank_df = self._enrich_with_shap(rank_df, top_n=20)
            
            # Select Top 10
            top10 = rank_df.head(10).copy()
            
            # Enrich with Stock Names (using local mapping)
            if 'stock_name' not in top10.columns or top10['stock_name'].isnull().any():
                logger.info("æ­£åœ¨æ·»åŠ è‚¡ç¥¨åç¨±...")
                from stock_names import get_stock_name
                
                names = []
                for _, row in top10.iterrows():
                    sid = str(row['stock_id'])
                    names.append(get_stock_name(sid))
                
                top10['stock_name'] = names
                # Update rank_df as well for completeness if needed (optional)

            # Save
            today_str = date if date else datetime.now().strftime('%Y-%m-%d')
            path = self.artifact_dir / f"ranking_{today_str}.csv"
            
            out_cols = ['stock_id', 'stock_name', 'close', 'final_score', 'model_prob', 'rule_score', 'reasons']
            # Ensure cols exist
            out_cols = [c for c in out_cols if c in top10.columns]
            
            top10[out_cols].to_csv(path, index=False, encoding='utf-8-sig')
            
            print(f"\nğŸ† Top 10 é¸è‚¡çµæœ (å« AI è§£é‡‹) ({today_str}):")
            print(top10[out_cols].to_string(index=False))
            print(f"\næª”æ¡ˆå·²å„²å­˜: {path}")
            
            # æ–°å¢ï¼šç”Ÿæˆçµæ§‹åŒ–åˆ†æå ±å‘Š
            try:
                print("\nğŸ“ ç”Ÿæˆçµæ§‹åŒ–åˆ†æå ±å‘Š...")
                report_gen = StockReportGenerator(artifacts_dir=str(self.artifact_dir))
                report_gen.generate_report(ranked_df=rank_df, features_df=history_df)
            except Exception as report_err:
                logger.warning(f"å ±å‘Šç”Ÿæˆå¤±æ•—ï¼ˆä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰: {report_err}")
            
        except Exception as e:
            logger.error(f"æ’ååŸ·è¡Œå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    ranker = StockRanker()
    try:
        ranker.load_model()
    except Exception as e:
        print(f"æ³¨æ„: {e}")
        
    ranker.run_ranking()
