#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agent B - æ¯æ—¥æ’åæ¨¡çµ„ (å¢å¼·ç‰ˆ)
è² è²¬é æ¸¬ã€è¦å‰‡è©•åˆ†ã€èåˆèˆ‡è¼¸å‡º Top10/Watchlist
"""

import pandas as pd
import numpy as np
import pickle
import yaml
from pathlib import Path
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler
import warnings

warnings.filterwarnings('ignore')

class StockRanker:
    """è‚¡ç¥¨æ’åå™¨ï¼Œæ”¯æ´ LightGBM é æ¸¬èˆ‡è¦å‰‡åˆ†æ•¸å¡èåˆ"""
    
    def __init__(self, data_dir: str = "data/clean", model_dir: str = "models",
                 artifact_dir: str = "artifacts", config_path: str = "config/signals.yaml"):
        """
        åˆå§‹åŒ–æ’åå™¨
        """
        self.data_dir = Path(data_dir)
        self.model_dir = Path(model_dir)
        self.artifact_dir = Path(artifact_dir)
        self.config_path = Path(config_path)
        self.model = None
        
        # è¼‰å…¥è¨­å®š
        self.config = self._load_config()
        self.weights = self.config['scoring']['weights']
        self.buy_threshold = self.config['scoring'].get('buy_threshold', 3)
        self.max_bearish = self.config['scoring'].get('max_bearish', -2)
        self.alpha = self.config['scoring'].get('alpha', 0.5)
        self.top_reasons_count = self.config['scoring'].get('top_reasons', 3)
        
        # å»ºç«‹å¿…è¦ç›®éŒ„
        self.artifact_dir.mkdir(parents=True, exist_ok=True)

    def _load_config(self) -> dict:
        """è¼‰å…¥ signals.yaml è¨­å®š"""
        if not self.config_path.exists():
            print(f"âš  æ‰¾ä¸åˆ°è¨­å®šæª” {self.config_path}ï¼Œä½¿ç”¨é è¨­å€¼")
            return {
                'scoring': {
                    'weights': {},
                    'buy_threshold': 3,
                    'max_bearish': -2,
                    'alpha': 0.5,
                    'top_reasons': 3
                }
            }
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def load_model(self, filename: str = "latest_lgbm.pkl"):
        """è¼‰å…¥ LightGBM æ¨¡å‹"""
        model_path = self.model_dir / filename
        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
        
        with open(model_path, 'rb') as f:
            self.model = pickle.load(f)
        print(f"âœ“ è¼‰å…¥æ¨¡å‹: {model_path}")
        return self.model

    def load_daily_data(self, target_date: str = None) -> tuple:
        """
        è¼‰å…¥ä»Šæ—¥ Universe, Features èˆ‡ Events
        """
        # è¼‰å…¥ parquet æª”æ¡ˆ
        try:
            features = pd.read_parquet(self.data_dir / "features.parquet")
            universe = pd.read_parquet(self.data_dir / "universe.parquet")
            events = pd.read_parquet(self.data_dir / "events.parquet")
        except FileNotFoundError as e:
            raise FileNotFoundError(f"å¿…è¦çš„è³‡æ–™æª”æ¡ˆç¼ºå¤±: {e}")

        # æ±ºå®šæ—¥æœŸ
        if target_date is None:
            target_date = features['date'].max()
            if isinstance(target_date, str):
                pass # already string
            else:
                 # Check if date is datetime object
                target_date = target_date.strftime("%Y-%m-%d")

        print(f"ğŸ“… è™•ç†æ—¥æœŸ: {target_date}")

        # ç¯©é¸ç•¶æ—¥è³‡æ–™
        def filter_date(df, date_col='date'):
            if df[date_col].dtype == 'object':
                return df[df[date_col] == target_date]
            else:
                # å‡è¨­æ˜¯ datetime
                return df[df[date_col].astype(str) == target_date]

        daily_features = filter_date(features)
        daily_universe = filter_date(universe)
        daily_events = filter_date(events)

        # åˆä½µ Universe èˆ‡ Features (Inner Join)
        # ç¢ºä¿ Universe æœ‰ 'name' æ¬„ä½ï¼Œè‹¥ç„¡å‰‡å˜—è©¦å¾å…¶ä»–ä¾†æºè£œæˆ–ç•™ç©º
        if 'name' not in daily_universe.columns:
            daily_universe['name'] = daily_universe['symbol'] # Fallback
            
        merged_df = daily_universe.merge(
            daily_features, on=['symbol', 'date'], how='inner'
        )
        
        # åˆä½µ Events (Left Join)
        merged_df = merged_df.merge(
            daily_events, on=['symbol', 'date'], how='left'
        )
        
        # å¡«å…… Events çš„ NaN ç‚º 0 (å‡è¨­ç„¡ç´€éŒ„å³ç„¡äº‹ä»¶)
        event_cols = [col for col in self.weights.keys() if col in events.columns]
        merged_df[event_cols] = merged_df[event_cols].fillna(0)

        print(f"âœ“ è³‡æ–™è¼‰å…¥å®Œæˆ: {len(merged_df)} ç­† (Universe + Features + Events)")
        return merged_df

    def calculate_scores(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è¨ˆç®—è¦å‰‡åˆ†æ•¸èˆ‡èåˆåˆ†æ•¸
        """
        df = df.copy()
        
        # 1. æ¨¡å‹åˆ†æ•¸ (Model Score)
        if self.model:
            # æ’é™¤éç‰¹å¾µæ¬„ä½
            exclude_cols = ['symbol', 'date', 'target', 'name', 'industry', 'market', 'status'] + \
                           list(self.weights.keys()) # æ’é™¤äº‹ä»¶æ¬„ä½
            feature_cols = [c for c in df.columns if c not in exclude_cols and c in self.model.feature_name()]
            
            # ç¢ºä¿ç‰¹å¾µå­˜åœ¨
            X = df[feature_cols]
            df['expected_return_5d'] = self.model.predict(X)
        else:
            df['expected_return_5d'] = 0.0

        # 2. è¦å‰‡åˆ†æ•¸ (Rule Score)
        pos_score = pd.Series(0.0, index=df.index)
        neg_score = pd.Series(0.0, index=df.index)
        
        for event, weight in self.weights.items():
            if event in df.columns:
                # ç¢ºä¿æ˜¯æ•¸å€¼ (0/1)
                triggered = df[event].astype(float) > 0
                score_contrib = triggered * abs(weight)
                
                if weight > 0:
                    pos_score += score_contrib
                else:
                    neg_score -= score_contrib # è² åˆ†ç´¯ç©
        
        df['pos_score'] = pos_score
        df['neg_score'] = neg_score
        df['rule_score'] = pos_score + neg_score
        
        # 3. åˆ†æ•¸èåˆ (Fusion)
        # Normalize rule score to be comparable to returns (e.g. divide by 100 or minmax)
        # ä½¿ç”¨ç°¡å–®ç¸®æ”¾ï¼šrule_score / 20 (å‡è¨­æ»¿åˆ†ç´„ 20) å¤§ç´„å°æ‡‰ 0~1 ä¹‹é–“ï¼Œå†ä¹˜ä¸Šé¡ä¼¼ return çš„ scale?
        # æˆ–æ˜¯ä¾ç…§æŒ‡ç¤º: normalize(rule_score)
        # é€™è£¡æ¡ç”¨ MinMax Scaling (ç•¶æ—¥) æ˜ å°„åˆ° [0, 1] å€é–“ï¼Œå†å¹³ç§»è‡³ [-0.5, 0.5] ä»¥ç¬¦åˆ alpha æ··åˆ?
        # ç‚ºäº†ç©©å¥ï¼Œæˆ‘å€‘å°‡ rule_score é™¤ä»¥ 100ï¼Œä½¿å…¶è½åœ¨ [-0.15, 0.15] å€é–“ï¼Œèˆ‡ return é¡ä¼¼
        # æˆ–è€…ä½¿ç”¨ Rank Percentile (0~1)
        
        df['rule_score_norm'] = df['rule_score'] / 100.0 
        
        # èåˆ: final = alpha * model + (1-alpha) * rule_norm
        df['final_score'] = self.alpha * df['expected_return_5d'] + (1 - self.alpha) * df['rule_score_norm']
        
        # 4. ä¼°ç®— Winrate (Sigmoid of final score scaled)
        # ç°¡å–® heuristic: 0.5 + tanh(score * k) / 2
        df['winrate'] = (1 / (1 + np.exp(-df['final_score'] * 20))).clip(0, 0.99)

        return df

    def generate_reasons_string(self, row) -> str:
        """
        ç”Ÿæˆç†ç”±å­—ä¸²
        """
        reasons = []
        
        # æ”¶é›†è§¸ç™¼çš„äº‹ä»¶
        triggered_events = []
        for event, weight in self.weights.items():
            if event in row and row[event] > 0:
                triggered_events.append((event, weight))
        
        # ä¾æ¬Šé‡çµ•å°å€¼æ’åº (å¤§åˆ°å°)
        triggered_events.sort(key=lambda x: abs(x[1]), reverse=True)
        
        # å– Top N
        top_events = triggered_events[:self.top_reasons_count]
        
        # è½‰æ›ç‚ºæ–‡å­—
        # æ¨¡æ¿æ˜ å°„ (Hardcoded for now based on instructions, can be moved to config)
        templates = {
            'break_20d_high': "çªç ´20æ—¥é«˜",
            'ma5_cross_ma20_up': "MA5ä¸Šç©¿MA20",
            'close_above_bb_mid': "ç«™ä¸Šå¸ƒæ—ä¸­è»Œ",
            'macd_bullish_cross': "MACDé‡‘å‰",
            'rsi_rebound_from_40': "RSIå›å‡",
            'gap_up_close_strong': "è·³ç©ºå¼·å‹¢",
            'volume_spike': "é‡èƒ½çªå¢",
            'revenue_momentum': "ç‡Ÿæ”¶å‹•èƒ½",
            'rev_yoy_positive': "ç‡Ÿæ”¶æˆé•·",
            'eps_accel': "EPSåŠ é€Ÿ",
            'lose_20d_low': "âš ç ´20æ—¥ä½",
            'ma5_cross_ma20_down': "âš MAæ­»å‰",
            'close_below_bb_mid': "âš ç ´å¸ƒæ—ä¸­è»Œ",
            'macd_bearish_cross': "âš MACDæ­»å‰",
            'rsi_break_below_50': "âš RSIè½‰å¼±",
            'long_upper_shadow': "âš é•·ä¸Šå½±ç·š"
        }
        
        for event, weight in top_events:
            name = templates.get(event, event)
            if weight < 0 and "âš " not in name:
                name = f"âš {name}"
            reasons.append(name)
            
        return " | ".join(reasons)

    def filter_and_label(self, df: pd.DataFrame) -> tuple:
        """
        ç¯©é¸æ¸…å–®ä¸¦æ¨™è¨˜ Buy Flag
        """
        # ç”Ÿæˆç†ç”±
        df['reasons'] = df.apply(self.generate_reasons_string, axis=1)
        
        # æ¨™è¨˜ Buy Flag
        # æ¢ä»¶: rule_score >= threshold AND rule_score > max_bearish
        # æ³¨æ„: max_bearish é€šå¸¸æ˜¯è² å€¼ (ä¾‹å¦‚ -2)ã€‚è‹¥æ˜¯ neg_score <= -2 å‰‡ç‚ºå¤ªå·®?
        # éœ€æ±‚: "rule_score > max_bearish" å¯èƒ½æ˜¯æŒ‡ neg_score ä¸æœƒå¤ªä½? 
        # åŸæ–‡: "rule_score >= buy_threshold ä¸” rule_score > max_bearish" -> 
        # é€™è£¡å‡è¨­ rule_score æœ¬èº«å°±æ˜¯ç¸½åˆ†ã€‚å¦‚æœ max_bearish æ˜¯å€‹åº•ç·š (e.g. -2)
        # é‚£éº¼ rule_score å¿…é ˆ > -2ã€‚ä½†é€šå¸¸ buy_threshold (e.g. 3) å·²ç¶“å¤§æ–¼ -2ã€‚
        # ä¹Ÿè¨±æ˜¯æŒ‡ "neg_score > max_bearish" (è² åˆ†ä¸è¦æ‰£å¤ªå¤š)?
        # ä¾æ“š prompt: "rule_score >= buy_threshold ä¸” rule_score > max_bearish"
        # ç…§å­—é¢å¯¦ä½œã€‚
        
        def check_buy(row):
            is_score_high = row['rule_score'] >= self.buy_threshold
            is_bearish_ok = row['rule_score'] > self.max_bearish # ä¼¼ä¹æœ‰é»å¤šé¤˜ï¼Œé™¤é buy_threshold < max_bearish
            # ä¹Ÿè¨± user æ„æ€æ˜¯: pos_sum >= threshold AND neg_sum > max_bearish ?
            # "è‹¥è² å‘ç¸½åˆ† â‰¤ -2ï¼Œç›´æ¥æ’é™¤" -> neg_score > -2
            
            # ä¿®æ­£é‚è¼¯ï¼šä¾æ“š "è‹¥è² å‘ç¸½åˆ† â‰¤ -2ï¼Œç›´æ¥æ’é™¤"
            is_neg_ok = row['neg_score'] > self.max_bearish
            
            return is_score_high and is_neg_ok

        df['buy_flag'] = df.apply(check_buy, axis=1)
        
        # æ’åº: ä¾ final_score é«˜åˆ°ä½
        df_sorted = df.sort_values('final_score', ascending=False)
        
        # è¼¸å‡ºæ¬„ä½
        out_cols = ['symbol', 'name', 'expected_return_5d', 'winrate', 
                    'final_score', 'rule_score', 'buy_flag', 'reasons']
        
        # Top 10: å¿…é ˆæ˜¯ Buy Flag = True çš„å‰ 10
        top10 = df_sorted[df_sorted['buy_flag'] == True].head(10)[out_cols].copy()
        
        # Watchlist: Buy Flag = False ä½† rule_score >= 0 æˆ– final_score é«˜çš„
        # é€™è£¡å–: æ²’æœ‰é€²å…¥ Top 10ï¼Œä½† final_score å‰ 50 å
        watchlist = df_sorted[~df_sorted.index.isin(top10.index)].head(50)[out_cols].copy()
        
        return top10, watchlist

    def save_results(self, top10: pd.DataFrame, watchlist: pd.DataFrame, target_date: str = None):
        """è¼¸å‡º CSV"""
        if target_date is None:
            target_date = datetime.now().strftime("%Y%m%d")
        else:
            target_date = target_date.replace('-', '')
            
        top10_path = self.artifact_dir / f"top10_{target_date}.csv"
        watch_path = self.artifact_dir / f"watchlist_{target_date}.csv"
        
        top10.rename(columns={'symbol': 'code'}, inplace=True)
        watchlist.rename(columns={'symbol': 'code'}, inplace=True)
        
        top10.to_csv(top10_path, index=False, encoding='utf-8-sig')
        watchlist.to_csv(watch_path, index=False, encoding='utf-8-sig')
        
        print(f"âœ“ è¼¸å‡º Top10: {top10_path} ({len(top10)} ç­†)")
        print(f"âœ“ è¼¸å‡º Watchlist: {watch_path} ({len(watchlist)} ç­†)")

def main():
    print("=" * 60)
    print("Agent B - æ¯æ—¥è‚¡ç¥¨æ’å (èåˆç‰ˆ)")
    print("=" * 60)
    
    ranker = StockRanker()
    
    try:
        # Load Model
        try:
            ranker.load_model()
        except FileNotFoundError:
            print("âš  ä½¿ç”¨ç„¡æ¨¡å‹æ¨¡å¼ (åƒ…è¦å‰‡è©•åˆ†)")
            
        # Load Data
        df = ranker.load_daily_data()
        
        # Calculate Scores
        scored_df = ranker.calculate_scores(df)
        
        # Filter & Rank
        top10, watchlist = ranker.filter_and_label(scored_df)
        
        # Save
        target_date = df['date'].iloc[0]
        ranker.save_results(top10, watchlist, str(target_date))
        
        print("\nâœ… åŸ·è¡Œå®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
