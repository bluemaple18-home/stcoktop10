#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Agent B - æ¨¡å‹è¨“ç·´æ¨¡çµ„
è² è²¬ LightGBM æ¨¡å‹è¨“ç·´ã€ç‰¹å¾µé‡è¦æ€§åˆ†æèˆ‡æ¨¡å‹æŒä¹…åŒ–
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from pathlib import Path
from datetime import datetime, timedelta
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import TimeSeriesSplit


class LightGBMTrainer:
    """LightGBM æ¨¡å‹è¨“ç·´å™¨ï¼Œæ”¯æ´ Walk-forward Validation"""
    
    def __init__(self, data_dir: str = "data/clean", model_dir: str = "models", 
                 artifact_dir: str = "artifacts", horizon: int = 5):
        """
        åˆå§‹åŒ–è¨“ç·´å™¨
        
        Args:
            data_dir: è³‡æ–™ç›®éŒ„
            model_dir: æ¨¡å‹å„²å­˜ç›®éŒ„
            artifact_dir: ç”¢å‡ºç‰©ç›®éŒ„
            horizon: é æ¸¬å¤©æ•¸ï¼ˆ5æ—¥å ±é…¬ï¼‰
        """
        self.data_dir = Path(data_dir)
        self.model_dir = Path(model_dir)
        self.artifact_dir = Path(artifact_dir)
        self.horizon = horizon
        self.model = None
        
        # å»ºç«‹å¿…è¦ç›®éŒ„
        self.model_dir.mkdir(parents=True, exist_ok=True)
        self.artifact_dir.mkdir(parents=True, exist_ok=True)
    
    def load_features(self, file_path: str = None) -> pd.DataFrame:
        """
        è¼‰å…¥ç‰¹å¾µè³‡æ–™
        
        Args:
            file_path: ç‰¹å¾µæª”æ¡ˆè·¯å¾‘ï¼Œé è¨­ç‚º data/clean/features.parquet
            
        Returns:
            ç‰¹å¾µ DataFrame
        """
        if file_path is None:
            file_path = self.data_dir / "features.parquet"
        else:
            file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"ç‰¹å¾µæª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        
        df = pd.read_parquet(file_path)
        
        # è¨˜æ†¶é«”å„ªåŒ–ï¼šå°‡ float64 é™è½‰ç‚º float32
        float_cols = df.select_dtypes(include=['float64']).columns
        if len(float_cols) > 0:
            df[float_cols] = df[float_cols].astype('float32')
            print(f"ğŸ“‰ å·²å°‡ {len(float_cols)} å€‹æ¬„ä½é™è½‰ç‚º float32 ä»¥ç¯€çœè¨˜æ†¶é«”")
            
        print(f"âœ“ è¼‰å…¥ç‰¹å¾µè³‡æ–™: {len(df)} ç­†, {len(df.columns)} æ¬„ä½")
        return df
    
    def generate_labels(self, df: pd.DataFrame, price_col: str = "close") -> pd.DataFrame:
        """
        ç”Ÿæˆæœªä¾† N æ—¥å ±é…¬æ¨™ç±¤ï¼ˆé¿å…è³‡æ–™æ´©æ¼ï¼‰
        
        Args:
            df: åŒ…å«åƒ¹æ ¼çš„ DataFrame (éœ€æœ‰ 'symbol' å’Œ 'date' æ¬„ä½)
            price_col: æ”¶ç›¤åƒ¹æ¬„ä½åç¨±
            
        Returns:
            åŒ…å« target æ¬„ä½çš„ DataFrame
        """
        df = df.copy()
        
        # ç¢ºä¿æŒ‰è‚¡ç¥¨ä»£ç¢¼å’Œæ—¥æœŸæ’åº
        df = df.sort_values(['symbol', 'date'])
        
        # è¨ˆç®—æœªä¾† N æ—¥æ”¶ç›¤åƒ¹
        df[f'future_{self.horizon}d_close'] = df.groupby('symbol')[price_col].shift(-self.horizon)
        
        # è¨ˆç®—å ±é…¬ç‡
        df['target'] = (df[f'future_{self.horizon}d_close'] / df[price_col]) - 1
        
        # ç§»é™¤ç„¡æ³•è¨ˆç®—æ¨™ç±¤çš„è³‡æ–™
        df_clean = df.dropna(subset=['target'])
        
        # ç§»é™¤è¼”åŠ©æ¬„ä½
        df_clean = df_clean.drop(columns=[f'future_{self.horizon}d_close'])
        
        print(f"âœ“ ç”Ÿæˆ {self.horizon} æ—¥å ±é…¬æ¨™ç±¤: {len(df_clean)} ç­†æœ‰æ•ˆè³‡æ–™")
        return df_clean
    
    def prepare_train_data(self, df: pd.DataFrame, exclude_cols: list = None):
        """
        æº–å‚™è¨“ç·´è³‡æ–™ï¼Œåˆ†é›¢ç‰¹å¾µèˆ‡æ¨™ç±¤
        
        Args:
            df: å®Œæ•´ DataFrame
            exclude_cols: è¦æ’é™¤çš„æ¬„ä½ï¼ˆå¦‚ symbol, date ç­‰ï¼‰
            
        Returns:
            X, y, feature_names
        """
        if exclude_cols is None:
            exclude_cols = ['symbol', 'date', 'target']
        
        # åˆ†é›¢æ¨™ç±¤
        y = df['target']
        
        # åˆ†é›¢ç‰¹å¾µ
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        X = df[feature_cols]
        
        print(f"âœ“ æº–å‚™è¨“ç·´è³‡æ–™: {len(X)} ç­†, {len(feature_cols)} å€‹ç‰¹å¾µ")
        return X, y, feature_cols
    
    def train_model(self, X: pd.DataFrame, y: pd.Series, params: dict = None):
        """
        è¨“ç·´ LightGBM æ¨¡å‹
        
        Args:
            X: ç‰¹å¾µ
            y: æ¨™ç±¤
            params: LightGBM åƒæ•¸
            
        Returns:
            è¨“ç·´å¥½çš„æ¨¡å‹
        """
        if params is None:
            params = {
                'objective': 'regression',
                'metric': 'rmse',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.05,
                'feature_fraction': 0.8,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1
            }
        
        # å»ºç«‹ LightGBM Dataset
        train_data = lgb.Dataset(X, label=y)
        
        # è¨“ç·´æ¨¡å‹
        print("â³ é–‹å§‹è¨“ç·´ LightGBM æ¨¡å‹...")
        self.model = lgb.train(
            params,
            train_data,
            num_boost_round=200,
            valid_sets=[train_data],
            valid_names=['train']
        )
        
        print("âœ“ æ¨¡å‹è¨“ç·´å®Œæˆ")
        return self.model
    
    def save_model(self, filename: str = "latest_lgbm.pkl"):
        """
        å„²å­˜æ¨¡å‹
        
        Args:
            filename: æ¨¡å‹æª”æ¡ˆåç¨±
        """
        if self.model is None:
            raise ValueError("å°šæœªè¨“ç·´æ¨¡å‹")
        
        model_path = self.model_dir / filename
        with open(model_path, 'wb') as f:
            pickle.dump(self.model, f)
        
        print(f"âœ“ æ¨¡å‹å·²å„²å­˜è‡³: {model_path}")
    
    def plot_feature_importance(self, top_n: int = 20, filename: str = "feature_importance.png"):
        """
        ç¹ªè£½ç‰¹å¾µé‡è¦æ€§åœ–è¡¨
        
        Args:
            top_n: é¡¯ç¤ºå‰ N å€‹é‡è¦ç‰¹å¾µ
            filename: åœ–è¡¨æª”å
        """
        if self.model is None:
            raise ValueError("å°šæœªè¨“ç·´æ¨¡å‹")
        
        # å–å¾—ç‰¹å¾µé‡è¦æ€§
        importance = self.model.feature_importance(importance_type='gain')
        feature_names = self.model.feature_name()
        
        # å»ºç«‹ DataFrame
        fi_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False).head(top_n)
        
        # ç¹ªåœ–
        plt.figure(figsize=(10, 8))
        sns.barplot(data=fi_df, x='importance', y='feature', palette='viridis')
        plt.title(f'Top {top_n} ç‰¹å¾µé‡è¦æ€§ (Gain)', fontsize=14, fontweight='bold')
        plt.xlabel('é‡è¦æ€§åˆ†æ•¸', fontsize=12)
        plt.ylabel('ç‰¹å¾µåç¨±', fontsize=12)
        plt.tight_layout()
        
        # å„²å­˜
        output_path = self.artifact_dir / filename
        plt.savefig(output_path, dpi=150)
        plt.close()
        
        print(f"âœ“ ç‰¹å¾µé‡è¦æ€§åœ–è¡¨å·²å„²å­˜è‡³: {output_path}")
        
        return fi_df


def main():
    """ä¸»ç¨‹å¼ï¼šåŸ·è¡Œå®Œæ•´è¨“ç·´æµç¨‹"""
    print("=" * 60)
    print("Agent B - LightGBM æ¨¡å‹è¨“ç·´")
    print("=" * 60)
    
    # åˆå§‹åŒ–è¨“ç·´å™¨
    trainer = LightGBMTrainer(horizon=5)
    
    try:
        # 1. è¼‰å…¥ç‰¹å¾µ
        df = trainer.load_features()
        
        # 2. ç”Ÿæˆæ¨™ç±¤
        df = trainer.generate_labels(df)
        
        # 3. æº–å‚™è¨“ç·´è³‡æ–™
        X, y, feature_names = trainer.prepare_train_data(df)
        
        # 4. è¨“ç·´æ¨¡å‹
        model = trainer.train_model(X, y)
        
        # 5. å„²å­˜æ¨¡å‹
        trainer.save_model()
        
        # 6. ç¹ªè£½ç‰¹å¾µé‡è¦æ€§
        trainer.plot_feature_importance()
        
        print("\nâœ… è¨“ç·´æµç¨‹å®Œæˆï¼")
        
    except FileNotFoundError as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        print("è«‹ç¢ºèª Agent A å·²ç”¢ç”Ÿ features.parquet")
    except Exception as e:
        print(f"\nâŒ è¨“ç·´å¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    main()
